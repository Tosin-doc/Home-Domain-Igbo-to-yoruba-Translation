{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import csv\n",
    "from docx import Document\n",
    "\n",
    "def read_docx_tab(tab, **kwargs):\n",
    "    vf = io.StringIO()\n",
    "    writer = csv.writer(vf)\n",
    "    for row in tab.rows:\n",
    "        writer.writerow(cell.text for cell in row.cells)\n",
    "    vf.seek(0)\n",
    "    return pd.read_csv(vf, **kwargs)\n",
    "\n",
    "def read_docx_tables(filename, tab_id=None, **kwargs):\n",
    "    \"\"\"\n",
    "    parse table(s) from a Word Document (.docx) into Pandas DataFrame(s)\n",
    "\n",
    "    Parameters:\n",
    "        filename:   file name of a Word Document\n",
    "\n",
    "        tab_id:     parse a single table with the index: [tab_id] (counting from 0).\n",
    "                    When [None] - return a list of DataFrames (parse all tables)\n",
    "\n",
    "        kwargs:     arguments to pass to `pd.read_csv()` function\n",
    "\n",
    "    Return: a single DataFrame if tab_id != None or a list of DataFrames otherwise\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    doc = Document(filename)\n",
    "    if tab_id is None:\n",
    "        return [read_docx_tab(tab, **kwargs) for tab in doc.tables]\n",
    "    else:\n",
    "        try:\n",
    "            return read_docx_tab(doc.tables[tab_id], **kwargs)\n",
    "        except IndexError:\n",
    "            print('Error: specified [tab_id]: {}  does not exist.'.format(tab_id))\n",
    "            raise\n",
    "\n",
    "            \n",
    "table = read_docx_tables(filename = 'Tabular.docx', tab_id = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S/N</th>\n",
       "      <th>ENG VERB</th>\n",
       "      <th>ENG VERB.1</th>\n",
       "      <th>PAST TENSE</th>\n",
       "      <th>PAST TENSE .1</th>\n",
       "      <th>PAST TENSE .2</th>\n",
       "      <th>English Sentence</th>\n",
       "      <th>IGBO SENTENCES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>FIND</td>\n",
       "      <td>FIND</td>\n",
       "      <td>FOUND</td>\n",
       "      <td>FOUND</td>\n",
       "      <td>FOUND</td>\n",
       "      <td>I found the book</td>\n",
       "      <td>Áchọ̀tárà ḿ ákwúkwọ́</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>DO</td>\n",
       "      <td>DO</td>\n",
       "      <td>DID</td>\n",
       "      <td>DID</td>\n",
       "      <td>DID</td>\n",
       "      <td>I did it</td>\n",
       "      <td>émèrè ḿ yá</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>MAKE</td>\n",
       "      <td>MAKE</td>\n",
       "      <td>MADE</td>\n",
       "      <td>MADE</td>\n",
       "      <td>MADE</td>\n",
       "      <td>He made  the cake</td>\n",
       "      <td>émèrè ḿ áchíchá ahù</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>GET</td>\n",
       "      <td>GET</td>\n",
       "      <td>GOT</td>\n",
       "      <td>GOT</td>\n",
       "      <td>GOT</td>\n",
       "      <td>I got home</td>\n",
       "      <td>énwò ḿ n'ụ́lọ̀</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>SAY</td>\n",
       "      <td>SAY</td>\n",
       "      <td>SAID</td>\n",
       "      <td>SAID</td>\n",
       "      <td>SAID</td>\n",
       "      <td>He said nothing</td>\n",
       "      <td>O kwụ́ghi ihé ọ bụ́lá</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S/N ENG VERB ENG VERB.1 PAST TENSE  PAST TENSE .1 PAST TENSE .2  \\\n",
       "0    1     FIND       FIND      FOUND         FOUND         FOUND    \n",
       "1    2      DO         DO         DID           DID           DID    \n",
       "2    3    MAKE       MAKE         MADE          MADE          MADE   \n",
       "3    4      GET        GET        GOT           GOT           GOT    \n",
       "4    5      SAY        SAY      SAID          SAID          SAID     \n",
       "\n",
       "   English Sentence         IGBO SENTENCES   \n",
       "0   I found the book   Áchọ̀tárà ḿ ákwúkwọ́  \n",
       "1          I did it              émèrè ḿ yá  \n",
       "2  He made  the cake    émèrè ḿ áchíchá ahù  \n",
       "3         I got home         énwò ḿ n'ụ́lọ̀  \n",
       "4   He said nothing   O kwụ́ghi ihé ọ bụ́lá  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['S/N', 'ENG VERB', 'ENG VERB.1', 'PAST TENSE ', 'PAST TENSE .1',\n",
       "       'PAST TENSE .2', 'English Sentence ', 'IGBO SENTENCES '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_table = table.drop(['S/N','ENG VERB.1','PAST TENSE .1','PAST TENSE .2'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENG VERB</th>\n",
       "      <th>PAST TENSE</th>\n",
       "      <th>English Sentence</th>\n",
       "      <th>IGBO SENTENCES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FIND</td>\n",
       "      <td>FOUND</td>\n",
       "      <td>I found the book</td>\n",
       "      <td>Áchọ̀tárà ḿ ákwúkwọ́</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DO</td>\n",
       "      <td>DID</td>\n",
       "      <td>I did it</td>\n",
       "      <td>émèrè ḿ yá</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAKE</td>\n",
       "      <td>MADE</td>\n",
       "      <td>He made  the cake</td>\n",
       "      <td>émèrè ḿ áchíchá ahù</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GET</td>\n",
       "      <td>GOT</td>\n",
       "      <td>I got home</td>\n",
       "      <td>énwò ḿ n'ụ́lọ̀</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SAY</td>\n",
       "      <td>SAID</td>\n",
       "      <td>He said nothing</td>\n",
       "      <td>O kwụ́ghi ihé ọ bụ́lá</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ENG VERB PAST TENSE   English Sentence         IGBO SENTENCES \n",
       "0     FIND      FOUND    I found the book   Áchọ̀tárà ḿ ákwúkwọ́\n",
       "1      DO         DID           I did it              émèrè ḿ yá\n",
       "2    MAKE         MADE  He made  the cake    émèrè ḿ áchíchá ahù\n",
       "3      GET        GOT          I got home         énwò ḿ n'ụ́lọ̀\n",
       "4      SAY      SAID     He said nothing   O kwụ́ghi ihé ọ bụ́lá"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_table = updated_table.dropna()\n",
    "updated_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = updated_table['English Sentence '], updated_table['IGBO SENTENCES ']\n",
    "raw_dataset = updated_table[['English Sentence ','IGBO SENTENCES ']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     I found the book\n",
       "1            I did it \n",
       "2    He made  the cake\n",
       "3           I got home\n",
       "Name: English Sentence , dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Áchọ̀tárà ḿ ákwúkwọ́\n",
       "1              émèrè ḿ yá\n",
       "2     émèrè ḿ áchíchá ahù\n",
       "3          énwò ḿ n'ụ́lọ̀\n",
       "Name: IGBO SENTENCES , dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "splited_x = [k.split() for k in x]\n",
    "splited_y = [k.split() for k in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['I', 'found', 'the', 'book'], ['Áchọ̀tárà', 'ḿ', 'ákwúkwọ́'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splited_x[0], splited_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I found the book', 'Áchọ̀tárà ḿ ákwúkwọ́')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_char(b):\n",
    "    characters = []\n",
    "    for l in b:\n",
    "        for m in l:\n",
    "            if m.lower() in characters:\n",
    "                pass\n",
    "            else:\n",
    "                characters.append(m.lower())\n",
    "    return sorted(characters)\n",
    "\n",
    "def output_char(b):\n",
    "    characters = []\n",
    "    for l in b:\n",
    "        for m in l:\n",
    "            if m in characters:\n",
    "                pass\n",
    "            else:\n",
    "                characters.append(m)\n",
    "    return sorted(characters)\n",
    "\n",
    "\n",
    "input_characters = input_char(splited_x)\n",
    "target_characters = output_char(splited_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, 185)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_characters), len(target_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'added', 'allowed', 'appeared', 'argument']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_characters[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Agaghị', 'Akwụ̀siri', 'Amụ̀tàrà', 'Anyị', 'Anụrụ']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_characters[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_encoder_tokens, num_of_decoder_tokens = len(input_characters), len(target_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_max(x):\n",
    "    list_length = []\n",
    "    for k in x:\n",
    "        length = len(k)\n",
    "        list_length.append(length)\n",
    "    return max(list_length)\n",
    "\n",
    "find_max(splited_x), find_max(splited_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05649717514124294"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio = 10/177\n",
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_input_char = {}\n",
    "ratio = 0.0565\n",
    "update = ratio\n",
    "#zero is for input-target 0\n",
    "for k in input_characters:\n",
    "    dict_input_char[k] = update\n",
    "    update = update+ ratio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05405405405405406"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ratio = 10/num_of_decoder_tokens\n",
    "output_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_output_char = {}\n",
    "output_ratio = 0.0541\n",
    "update = output_ratio\n",
    "#zero is for input-target 0\n",
    "for k in target_characters:\n",
    "    dict_output_char[k] = update\n",
    "    update = update+ output_ratio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad the data\n",
    "\n",
    "def padding(x, val):\n",
    "    copy_x = x.copy()\n",
    "    for i,k in enumerate(x):\n",
    "        if len(k) <val:\n",
    "            dif = val- len(k)\n",
    "            list_diff = [' ']*dif\n",
    "            for k in range(dif):\n",
    "                copy_x[i].append(' ')\n",
    "        else:\n",
    "            pass\n",
    "    return copy_x\n",
    "\n",
    "copy_splited_x = padding(splited_x,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_splited_y = padding(splited_y,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data is of shape 5\n",
    "# output data is of shape 7\n",
    "dict_input_char[' '] = 0.000\n",
    "dict_output_char[' '] = 0.000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_input_data(data):\n",
    "    for k,l in enumerate(data):\n",
    "        for i,j in enumerate(l):\n",
    "            data[k][i] = dict_input_char[j.lower()]\n",
    "    return data\n",
    "\n",
    "encoded_input_data = encode_input_data(copy_splited_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoded_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_target_data(data):\n",
    "    for k,l in enumerate(data):\n",
    "        for i,j in enumerate(l):\n",
    "            data[k][i] = dict_output_char[j]\n",
    "    return data\n",
    "\n",
    "encoded_target_data = encode_target_data(copy_splited_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4.463500000000006, 3.277000000000005, 8.81399999999999, 0.8475, 0.0],\n",
       " [4.463500000000006, 2.1470000000000007, 4.802500000000005, 0.0, 0.0],\n",
       " [3.9550000000000076, 5.819500000000001, 8.81399999999999, 1.1865, 0.0],\n",
       " [4.463500000000006, 3.559500000000006, 4.3505000000000065, 0.0, 0.0],\n",
       " [3.9550000000000076, 7.796999999999993, 6.666999999999997, 0.0, 0.0]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7.8445000000000045,\n",
       "  8.980600000000004,\n",
       "  8.331400000000004,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [8.601900000000004, 8.980600000000004, 7.519900000000004, 0.0, 0.0, 0.0, 0.0],\n",
       " [8.601900000000004,\n",
       "  8.980600000000004,\n",
       "  8.115000000000004,\n",
       "  0.9197000000000002,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [8.656000000000004,\n",
       "  8.980600000000004,\n",
       "  4.9772000000000025,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.8115000000000001,\n",
       "  3.841100000000002,\n",
       "  2.9214000000000016,\n",
       "  9.467500000000005,\n",
       "  1.5148000000000006,\n",
       "  0.0,\n",
       "  0.0]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_target_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe\n",
    "\n",
    "def create_frame(x,y, index = 0):\n",
    "    a,b,c,d,e, target = [],[],[],[],[],[]\n",
    "    \n",
    "    for l,m in zip(x,y):\n",
    "        a.append(l[0])\n",
    "        b.append(l[1])\n",
    "        c.append(l[2])\n",
    "        d.append(l[3])\n",
    "        e.append(l[4])\n",
    "        target.append(m[index])\n",
    "    dict_frame = {'a':a,'b':b,'c':c,'d':d,'e':e}\n",
    "    y = {'target': target}\n",
    "    \n",
    "    return pd.DataFrame(dict_frame), np.array(target)\n",
    "\n",
    "x0, y0 = create_frame(encoded_input_data,encoded_target_data, index = 0)\n",
    "x1, y1 = create_frame(encoded_input_data,encoded_target_data, index = 1)\n",
    "x2, y2 = create_frame(encoded_input_data,encoded_target_data, index = 2)\n",
    "x3, y3 = create_frame(encoded_input_data,encoded_target_data, index = 3)\n",
    "x4, y4 = create_frame(encoded_input_data,encoded_target_data, index = 4)\n",
    "x5, y5 = create_frame(encoded_input_data,encoded_target_data, index = 5)\n",
    "x6, y6 = create_frame(encoded_input_data,encoded_target_data, index = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train0, x_test0, y_train0, y_test0 = train_test_split(x0, y0, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is:  1.0\n",
      "The test accuracy is:  -2.3239361993152285\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "lr0 = DecisionTreeRegressor()\n",
    "lr0.fit(x_train0, y_train0)\n",
    "\n",
    "print('The training accuracy is: ',lr0.score(x_train0, y_train0))\n",
    "print('The test accuracy is: ',lr0.score(x_test0, y_test0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(x1, y1, test_size = 0.2, random_state = 42)\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2, y2, test_size = 0.2, random_state = 42)\n",
    "x_train3, x_test3, y_train3, y_test3 = train_test_split(x3, y3, test_size = 0.2, random_state = 42)\n",
    "x_train4, x_test4, y_train4, y_test4 = train_test_split(x4, y4, test_size = 0.2, random_state = 42)\n",
    "x_train5, x_test5, y_train5, y_test5 = train_test_split(x5, y5, test_size = 0.2, random_state = 42)\n",
    "x_train6, x_test6, y_train6, y_test6 = train_test_split(x6, y6, test_size = 0.2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is:  1.0\n",
      "The test accuracy is:  -0.4749105176211456\n"
     ]
    }
   ],
   "source": [
    "lr1 = DecisionTreeRegressor()\n",
    "lr1.fit(x_train1, y_train1)\n",
    "\n",
    "print('The training accuracy is: ',lr1.score(x_train1, y_train1))\n",
    "print('The test accuracy is: ',lr1.score(x_test1, y_test1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is:  1.0\n",
      "The test accuracy is:  -0.13692036920883344\n"
     ]
    }
   ],
   "source": [
    "lr2 = DecisionTreeRegressor()\n",
    "lr2.fit(x_train2, y_train2)\n",
    "\n",
    "print('The training accuracy is: ',lr2.score(x_train2, y_train2))\n",
    "print('The test accuracy is: ',lr2.score(x_test2, y_test2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is:  1.0\n",
      "The test accuracy is:  -1.3598738941165367\n"
     ]
    }
   ],
   "source": [
    "lr3 = DecisionTreeRegressor()\n",
    "lr3.fit(x_train3, y_train3)\n",
    "\n",
    "print('The training accuracy is: ',lr3.score(x_train3, y_train3))\n",
    "print('The test accuracy is: ',lr3.score(x_test3, y_test3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is:  1.0\n",
      "The test accuracy is:  -2.474303514900809\n"
     ]
    }
   ],
   "source": [
    "lr4 = DecisionTreeRegressor()\n",
    "lr4.fit(x_train4, y_train4)\n",
    "\n",
    "print('The training accuracy is: ',lr4.score(x_train4, y_train4))\n",
    "print('The test accuracy is: ',lr4.score(x_test4, y_test4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is:  1.0\n",
      "The test accuracy is:  -0.08912632744804205\n"
     ]
    }
   ],
   "source": [
    "lr5 = DecisionTreeRegressor()\n",
    "lr5.fit(x_train5, y_train5)\n",
    "\n",
    "print('The training accuracy is: ',lr5.score(x_train5, y_train5))\n",
    "print('The test accuracy is: ',lr5.score(x_test5, y_test5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is:  1.0\n",
      "The test accuracy is:  -0.05555555555555558\n"
     ]
    }
   ],
   "source": [
    "lr6 = DecisionTreeRegressor()\n",
    "lr6.fit(x_train6, y_train6)\n",
    "\n",
    "print('The training accuracy is: ',lr6.score(x_train6, y_train6))\n",
    "print('The test accuracy is: ',lr6.score(x_test6, y_test6))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\user\\\\Desktop\\\\NLP\\\\models/dtr//lr6dtr.pkl']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib, os\n",
    "current_dir = os.getcwd()\n",
    "save_directory = os.path.join(current_dir, 'models/dtr/')\n",
    "if not os.path.exists(save_directory):\n",
    "    os.makedirs(save_directory)\n",
    "joblib.dump(lr0, save_directory+'/lr0dtr.pkl')\n",
    "joblib.dump(lr1, save_directory+'/lr1dtr.pkl')\n",
    "joblib.dump(lr2, save_directory+'/lr2dtr.pkl')\n",
    "joblib.dump(lr3, save_directory+'/lr3dtr.pkl')\n",
    "joblib.dump(lr4, save_directory+'/lr4dtr.pkl')\n",
    "joblib.dump(lr5, save_directory+'/lr5dtr.pkl')\n",
    "joblib.dump(lr6, save_directory+'/lr6dtr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\user\\\\Desktop\\\\NLP\\\\models/dtr//dict_output_char.pkl']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write the dict_input_char\n",
    "joblib.dump(dict_input_char, save_directory+'/dict_input_char.pkl')\n",
    "joblib.dump(dict_output_char, save_directory+'/dict_output_char.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user\\\\Desktop\\\\NLP'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dict_input_char.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-1516d769a777>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#os.chdir(os.getcwd() +'/models/dtr')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0minput_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dict_input_char.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0moutput_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dict_output_char.pkl'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlr0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lr0dtr.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dict_input_char.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "#os.chdir(os.getcwd() +'/models/dtr')\n",
    "input_dict = pickle.load(open('dict_input_char.pkl', 'rb'))\n",
    "output_dict = pickle.load(open('dict_output_char.pkl','rb'))\n",
    "lr0 = pickle.load(open('lr0dtr.pkl', 'rb'))\n",
    "lr1 = pickle.load(open('lr1dtr.pkl', 'rb'))\n",
    "lr2 = pickle.load(open('lr2dtr.pkl', 'rb'))\n",
    "lr3 = pickle.load(open('lr3dtr.pkl', 'rb'))\n",
    "lr4 = pickle.load(open('lr4dtr.pkl', 'rb'))\n",
    "lr5 = pickle.load(open('lr5dtr.pkl', 'rb'))\n",
    "lr6 = pickle.load(open('lr6dtr.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.463500000000006, 2.1470000000000007, 4.802500000000005, 0.0, 0.0]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def encode_input_data(data):\n",
    "    data = data.split()\n",
    "    \n",
    "    data_length = len(data)\n",
    "    if data_length <5:\n",
    "        diff = 5 - data_length\n",
    "        for k in range(diff):\n",
    "            data.append(' ')\n",
    "    for i,j in enumerate(data):\n",
    "        data[i] = dict_input_char[j.lower()]\n",
    "    return data\n",
    "\n",
    "input_test = 'I did it'\n",
    "encoded_input_data = encode_input_data(input_test)\n",
    "encoded_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.601900000000004, 8.980600000000004, 7.519900000000004, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_encoder(data):\n",
    "    data = np.array(data).reshape(1,-1)\n",
    "    p0 = lr0.predict(data)\n",
    "    p1 = lr1.predict(data)\n",
    "    p2 = lr2.predict(data)\n",
    "    p3 = lr3.predict(data)\n",
    "    p4 = lr4.predict(data)\n",
    "    p5 = lr5.predict(data)\n",
    "    p6 = lr6.predict(data)\n",
    "    return [float(p0),float(p1),float(p2),float(p3),float(p4),float(p5),float(p6)]\n",
    "\n",
    "prediction = predict_encoder(encoded_input_data)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0541"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dict_output_char.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def three_dp(val):\n",
    "    val_str = str(val)\n",
    "    val_length = len(val_str)\n",
    "    if val_length <5:\n",
    "        diff = 5 - val_length\n",
    "        for k in range(diff):\n",
    "            val_str = val_str +'0'\n",
    "        cut_val = val_str\n",
    "    else:\n",
    "        cut_val = val_str[:5]\n",
    "    return float(cut_val)\n",
    "three_dp(3.10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ḿ'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_value(value):\n",
    "    va = three_dp(0.0541/2)\n",
    "    upper_range, lower_range = value +va, value - va\n",
    "    key = ''\n",
    "    for i,k in zip(list(dict_output_char.keys()), dict_output_char.values()):\n",
    "        if k < three_dp(value) and k > lower_range:\n",
    "            key = i\n",
    "        elif k > three_dp(value) and k < upper_range:\n",
    "            key = i\n",
    "        else:\n",
    "            continue\n",
    "    return key\n",
    "get_value(8.980600000000004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' émèrè ḿ yá    '"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def model_decoder(data):\n",
    "    result = []\n",
    "    for k in data:\n",
    "        result.append(get_value(k))\n",
    "    output = ''\n",
    "    for k in result:\n",
    "        output += ' ' +k\n",
    "    return output\n",
    "\n",
    "model_decoder(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ọ́ rụ̀sìrì ọ́rụ́ ire   \n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "\n",
    "def encode_input_data(data):\n",
    "    data = data.split()\n",
    "    \n",
    "    data_length = len(data)\n",
    "    if data_length <5:\n",
    "        diff = 5 - data_length\n",
    "        for k in range(diff):\n",
    "            data.append(' ')\n",
    "    for i,j in enumerate(data):\n",
    "        data[i] = dict_input_char[j.lower()]\n",
    "    return data\n",
    "\n",
    "def predict_encoder(data):\n",
    "    data = np.array(data).reshape(1,-1)\n",
    "    p0 = lr0.predict(data)\n",
    "    p1 = lr1.predict(data)\n",
    "    p2 = lr2.predict(data)\n",
    "    p3 = lr3.predict(data)\n",
    "    p4 = lr4.predict(data)\n",
    "    p5 = lr5.predict(data)\n",
    "    p6 = lr6.predict(data)\n",
    "    return [float(p0),float(p1),float(p2),float(p3),float(p4),float(p5),float(p6)]\n",
    "\n",
    "\n",
    "def three_dp(val):\n",
    "    val_str = str(val)\n",
    "    val_length = len(val_str)\n",
    "    if val_length <5:\n",
    "        diff = 5 - val_length\n",
    "        for k in range(diff):\n",
    "            val_str = val_str +'0'\n",
    "        cut_val = val_str\n",
    "    else:\n",
    "        cut_val = val_str[:5]\n",
    "    return float(cut_val)\n",
    "\n",
    "\n",
    "def get_value(value):\n",
    "    va = three_dp(0.0541/2)\n",
    "    upper_range, lower_range = value +va, value - va\n",
    "    key = ''\n",
    "    for i,k in zip(list(dict_output_char.keys()), dict_output_char.values()):\n",
    "        if k < three_dp(value) and k > lower_range:\n",
    "            key = i\n",
    "        elif k > three_dp(value) and k < upper_range:\n",
    "            key = i\n",
    "        else:\n",
    "            continue\n",
    "    return key\n",
    "\n",
    "def model_decoder(data):\n",
    "    result = []\n",
    "    for k in data:\n",
    "        result.append(get_value(k))\n",
    "    output = ''\n",
    "    for k in result:\n",
    "        output += ' ' +k\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "    import pickle\n",
    "#os.chdir(os.getcwd() +'/models/dtr')\n",
    "#input_dict = pickle.load(open('dict_input_char.pkl', 'rb'))\n",
    "#output_dict = pickle.load(open('dict_output_char.pkl','rb'))\n",
    "#lr0 = pickle.load(open('lr0dtr.pkl', 'rb'))\n",
    "#lr1 = pickle.load(open('lr1dtr.pkl', 'rb'))\n",
    "#lr2 = pickle.load(open('lr2dtr.pkl', 'rb'))\n",
    "#lr3 = pickle.load(open('lr3dtr.pkl', 'rb'))\n",
    "#lr4 = pickle.load(open('lr4dtr.pkl', 'rb'))\n",
    "#lr5 = pickle.load(open('lr5dtr.pkl', 'rb'))\n",
    "#lr6 = pickle.load(open('lr6dtr.pkl', 'rb'))\n",
    "\n",
    "\n",
    "\n",
    "def main(string):\n",
    "    val = ''\n",
    "    encoded_input_data = encode_input_data(string)\n",
    "    prediction = predict_encoder(encoded_input_data)\n",
    "    val = model_decoder(prediction)\n",
    "    return val\n",
    "\n",
    "\n",
    "if __name__== '__main__':\n",
    "    string = 'He worked hard'\n",
    "    result = main(string)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15         He worked hard \n",
       "16    He knocked the door \n",
       "17    I included his name \n",
       "18            I helped him\n",
       "19      He provided for us\n",
       "Name: English Sentence , dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[15:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15      Ọ́ rụ̀sìrì ọ́rụ́ ire\n",
       "16    Ọ kụrụ áká n'ọnú ụ́zọ̀\n",
       "17       Ḿ tinyèrè yá áhà yá\n",
       "18           Ḿ nyeèrè yá áká\n",
       "19              O nyèrè anyí\n",
       "Name: IGBO SENTENCES , dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[15:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
